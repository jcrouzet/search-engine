import java.io.*;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Set;
import java.util.TreeMap;

import tools.Normalizer;
import java.io.*;
import java.io.*;
public class Index {


	public File corpus;
	public Normalizer normalizer;


	public Index(Normalizer normalizer, File corpus)
	{
		this.normalizer = normalizer;

		this.corpus = corpus;
	}



	public void  getIndex() throws IOException {

		// Create the index_file	

		//  get the occurence of each term in each document
		HashMap<String, HashMap<String, Integer>> tf = new HashMap<String, HashMap<String, Integer>>();
		int NumberOfDocument = 0 ;

		if (corpus.isDirectory()) {
			// get all the files of the directory in order to Calculate of Tf (frequency terms)
			File [] files_corpus = corpus.listFiles();
			for (File file : files_corpus)
			{
				ArrayList<String> words = normalizer.normalize(file);
				
				//The hash code is then used as the index at which the data associated with the key is stored. 
				//the transformation of the key into its hash code is performed automatically.
				//we use a hashset for no have  2 occurences of the term
				
				HashSet<String> wordsInFile = new HashSet<String> (words) ;
				for(String word: wordsInFile)
				{
					word = word.toLowerCase();
					//  word is null
					if (!wordsInFile.contains(word))
					{
						HashMap<String, Integer> value = tf.get(word); 
	
						if(value == null) {

							//The frequency(Collection<?>, Object) method is used to get the number of elements
							//in the specified collection equal to the specified object.
							// example: https://www.tutorialspoint.com/java/util/collections_frequency.htm
							value.put(file.getName(), Collections.frequency(words, word));
							tf.put(word,value);
						}

					}	
				}
				NumberOfDocument ++ ;

			}		
		}
		// Calcul of weights tf_idf 
		// list of terms on orders alphabetiques ( that means the terms of the tf calculated before)
	Set<String> terms= new TreeMap<String, HashMap<String, Integer>>(tf).keySet();
//		for ( String word : terms)
//		{
//			// the value of tf is a hashMap (Doc,occurence)
//			HashMap<String, Integer> documents = tf.get(word);
//			HashMap<String, Float> tf_idf = new HashMap<String, Float>();

	//	}
		
		
	}	
}
